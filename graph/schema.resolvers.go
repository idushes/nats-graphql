package graph

// This file will be automatically regenerated based on the schema, any resolver
// implementations
// will be copied through when generating and any unknown code will be moved to the end.
// Code generated by github.com/99designs/gqlgen version v0.17.86

import (
	"context"
	"errors"
	"fmt"
	"nats-graphql/graph/model"
	"time"

	"github.com/nats-io/nats.go/jetstream"
)

// KvCreate is the resolver for the kvCreate field.
func (r *mutationResolver) KvCreate(ctx context.Context, bucket string, history *int, ttl *int, storage *string) (*model.KeyValue, error) {
	cfg := jetstream.KeyValueConfig{
		Bucket: bucket,
	}

	if history != nil {
		cfg.History = uint8(*history)
	}
	if ttl != nil {
		cfg.TTL = time.Duration(*ttl) * time.Second
	}
	if storage != nil {
		switch *storage {
		case "memory":
			cfg.Storage = jetstream.MemoryStorage
		default:
			cfg.Storage = jetstream.FileStorage
		}
	}

	kv, err := r.JS.CreateKeyValue(ctx, cfg)
	if err != nil {
		return nil, err
	}

	status, err := kv.Status(ctx)
	if err != nil {
		return nil, err
	}

	ttlSec := int(status.TTL().Seconds())
	return &model.KeyValue{
		Bucket:       status.Bucket(),
		History:      int(status.History()),
		TTL:          ttlSec,
		Storage:      status.BackingStore(),
		Bytes:        int(status.Bytes()),
		Values:       int(status.Values()),
		IsCompressed: status.IsCompressed(),
	}, nil
}

// KvPut is the resolver for the kvPut field.
func (r *mutationResolver) KvPut(ctx context.Context, bucket string, key string, value string) (*model.KVEntry, error) {
	kv, err := r.JS.KeyValue(ctx, bucket)
	if err != nil {
		return nil, err
	}

	rev, err := kv.Put(ctx, key, []byte(value))
	if err != nil {
		return nil, err
	}

	// Fetch the entry back to get the full metadata
	entry, err := kv.GetRevision(ctx, key, rev)
	if err != nil {
		return nil, err
	}

	return &model.KVEntry{
		Key:      entry.Key(),
		Value:    string(entry.Value()),
		Revision: int(entry.Revision()),
		Created:  entry.Created().Format(time.RFC3339),
	}, nil
}

// KvDelete is the resolver for the kvDelete field.
func (r *mutationResolver) KvDelete(ctx context.Context, bucket string, key string) (bool, error) {
	kv, err := r.JS.KeyValue(ctx, bucket)
	if err != nil {
		return false, err
	}

	if err := kv.Delete(ctx, key); err != nil {
		return false, err
	}

	return true, nil
}

// KvPurge is the resolver for the kvPurge field.
func (r *mutationResolver) KvPurge(ctx context.Context, bucket string, key string) (bool, error) {
	kv, err := r.JS.KeyValue(ctx, bucket)
	if err != nil {
		return false, err
	}
	err = kv.Purge(ctx, key)
	if err != nil {
		return false, err
	}
	return true, nil
}

// KvDeleteBucket is the resolver for the kvDeleteBucket field.
func (r *mutationResolver) KvDeleteBucket(ctx context.Context, bucket string) (bool, error) {
	err := r.JS.DeleteKeyValue(ctx, bucket)
	if err != nil {
		return false, err
	}
	return true, nil
}

// KvUpdate is the resolver for the kvUpdate field.
func (r *mutationResolver) KvUpdate(ctx context.Context, bucket string, history *int, ttl *int) (*model.KeyValue, error) {
	kv, err := r.JS.KeyValue(ctx, bucket)
	if err != nil {
		return nil, err
	}

	status, err := kv.Status(ctx)
	if err != nil {
		return nil, err
	}

	cfg := jetstream.KeyValueConfig{
		Bucket:  bucket,
		History: uint8(status.History()),
		TTL:     status.TTL(),
		Storage: jetstream.FileStorage,
	}
	if status.BackingStore() == "JetStream" || status.BackingStore() == "Memory" {
		if status.BackingStore() == "Memory" {
			cfg.Storage = jetstream.MemoryStorage
		}
	}

	if history != nil {
		cfg.History = uint8(*history)
	}
	if ttl != nil {
		cfg.TTL = time.Duration(*ttl) * time.Second
	}

	updatedKV, err := r.JS.UpdateKeyValue(ctx, cfg)
	if err != nil {
		return nil, err
	}

	updatedStatus, err := updatedKV.Status(ctx)
	if err != nil {
		return nil, err
	}

	ttlSec := int(updatedStatus.TTL().Seconds())
	return &model.KeyValue{
		Bucket:       updatedStatus.Bucket(),
		History:      int(updatedStatus.History()),
		TTL:          ttlSec,
		Storage:      updatedStatus.BackingStore(),
		Bytes:        int(updatedStatus.Bytes()),
		Values:       int(updatedStatus.Values()),
		IsCompressed: updatedStatus.IsCompressed(),
	}, nil
}

// StreamCreate is the resolver for the streamCreate field.
func (r *mutationResolver) StreamCreate(ctx context.Context, name string, subjects []string, retention *string, storage *string, maxConsumers *int, maxMsgs *int, maxBytes *int, maxAge *int, replicas *int) (*model.StreamInfo, error) {
	cfg := jetstream.StreamConfig{
		Name:     name,
		Subjects: subjects,
	}

	if retention != nil {
		switch *retention {
		case "interest":
			cfg.Retention = jetstream.InterestPolicy
		case "workqueue":
			cfg.Retention = jetstream.WorkQueuePolicy
		default:
			cfg.Retention = jetstream.LimitsPolicy
		}
	}

	if storage != nil && *storage == "memory" {
		cfg.Storage = jetstream.MemoryStorage
	}

	if maxConsumers != nil {
		cfg.MaxConsumers = *maxConsumers
	}
	if maxMsgs != nil {
		cfg.MaxMsgs = int64(*maxMsgs)
	}
	if maxBytes != nil {
		cfg.MaxBytes = int64(*maxBytes)
	}
	if maxAge != nil {
		cfg.MaxAge = time.Duration(*maxAge) * time.Second
	}
	if replicas != nil {
		cfg.Replicas = *replicas
	}

	si, err := r.JS.CreateStream(ctx, cfg)
	if err != nil {
		return nil, err
	}

	info := si.CachedInfo()

	return &model.StreamInfo{
		Name:         info.Config.Name,
		Subjects:     info.Config.Subjects,
		Retention:    info.Config.Retention.String(),
		MaxConsumers: info.Config.MaxConsumers,
		MaxMsgs:      int(info.Config.MaxMsgs),
		MaxBytes:     int(info.Config.MaxBytes),
		MaxAge:       int(info.Config.MaxAge / time.Second),
		Storage:      info.Config.Storage.String(),
		Replicas:     info.Config.Replicas,
		Messages:     int(info.State.Msgs),
		Bytes:        int(info.State.Bytes),
		Consumers:    info.State.Consumers,
		Created:      info.Created.Format(time.RFC3339),
		Sources:      mapSources(info.Sources),
	}, nil
}

// StreamDelete is the resolver for the streamDelete field.
func (r *mutationResolver) StreamDelete(ctx context.Context, name string) (bool, error) {
	err := r.JS.DeleteStream(ctx, name)
	if err != nil {
		return false, err
	}
	return true, nil
}

// StreamPurge is the resolver for the streamPurge field.
func (r *mutationResolver) StreamPurge(ctx context.Context, name string, subject *string) (bool, error) {
	s, err := r.JS.Stream(ctx, name)
	if err != nil {
		return false, err
	}
	var opts []jetstream.StreamPurgeOpt
	if subject != nil && *subject != "" {
		opts = append(opts, jetstream.WithPurgeSubject(*subject))
	}
	if err := s.Purge(ctx, opts...); err != nil {
		return false, err
	}
	return true, nil
}

// StreamUpdate is the resolver for the streamUpdate field.
func (r *mutationResolver) StreamUpdate(ctx context.Context, name string, subjects []string, maxConsumers *int, maxMsgs *int, maxBytes *int, maxAge *int, replicas *int) (*model.StreamInfo, error) {
	s, err := r.JS.Stream(ctx, name)
	if err != nil {
		return nil, err
	}

	sInfo, err := s.Info(ctx)
	if err != nil {
		return nil, err
	}

	cfg := sInfo.Config

	if len(subjects) > 0 {
		cfg.Subjects = subjects
	}
	if maxConsumers != nil {
		cfg.MaxConsumers = *maxConsumers
	}
	if maxMsgs != nil {
		cfg.MaxMsgs = int64(*maxMsgs)
	}
	if maxBytes != nil {
		cfg.MaxBytes = int64(*maxBytes)
	}
	if maxAge != nil {
		cfg.MaxAge = time.Duration(*maxAge) * time.Second
	}
	if replicas != nil {
		cfg.Replicas = *replicas
	}

	si, err := r.JS.UpdateStream(ctx, cfg)
	if err != nil {
		return nil, err
	}

	info := si.CachedInfo()

	return &model.StreamInfo{
		Name:         info.Config.Name,
		Subjects:     info.Config.Subjects,
		Retention:    info.Config.Retention.String(),
		MaxConsumers: info.Config.MaxConsumers,
		MaxMsgs:      int(info.Config.MaxMsgs),
		MaxBytes:     int(info.Config.MaxBytes),
		MaxAge:       int(info.Config.MaxAge / time.Second),
		Storage:      info.Config.Storage.String(),
		Replicas:     info.Config.Replicas,
		Messages:     int(info.State.Msgs),
		Bytes:        int(info.State.Bytes),
		Consumers:    info.State.Consumers,
		Created:      info.Created.Format(time.RFC3339),
		Sources:      mapSources(info.Sources),
	}, nil
}

// StreamCopy is the resolver for the streamCopy field.
func (r *mutationResolver) StreamCopy(ctx context.Context, name string, sources []*model.StreamSourceInput, subjects []string, retention *string, storage *string, maxConsumers *int, maxMsgs *int, maxBytes *int, maxAge *int, replicas *int) (*model.StreamInfo, error) {
	if len(sources) == 0 {
		return nil, fmt.Errorf("at least one source stream is required")
	}

	// Map input sources to JetStream StreamSource configs
	jsSources := make([]*jetstream.StreamSource, len(sources))
	for i, src := range sources {
		ss := &jetstream.StreamSource{
			Name: src.Name,
		}
		if src.FilterSubject != nil && *src.FilterSubject != "" {
			ss.FilterSubject = *src.FilterSubject
		}
		jsSources[i] = ss
	}

	cfg := jetstream.StreamConfig{
		Name:    name,
		Sources: jsSources,
	}

	if len(subjects) > 0 {
		cfg.Subjects = subjects
	}

	if retention != nil {
		switch *retention {
		case "interest":
			cfg.Retention = jetstream.InterestPolicy
		case "workqueue":
			cfg.Retention = jetstream.WorkQueuePolicy
		default:
			cfg.Retention = jetstream.LimitsPolicy
		}
	}

	if storage != nil && *storage == "memory" {
		cfg.Storage = jetstream.MemoryStorage
	}

	if maxConsumers != nil {
		cfg.MaxConsumers = *maxConsumers
	}
	if maxMsgs != nil {
		cfg.MaxMsgs = int64(*maxMsgs)
	}
	if maxBytes != nil {
		cfg.MaxBytes = int64(*maxBytes)
	}
	if maxAge != nil {
		cfg.MaxAge = time.Duration(*maxAge) * time.Second
	}
	if replicas != nil {
		cfg.Replicas = *replicas
	}

	si, err := r.JS.CreateStream(ctx, cfg)
	if err != nil {
		return nil, err
	}

	info := si.CachedInfo()

	return &model.StreamInfo{
		Name:         info.Config.Name,
		Subjects:     info.Config.Subjects,
		Retention:    info.Config.Retention.String(),
		MaxConsumers: info.Config.MaxConsumers,
		MaxMsgs:      int(info.Config.MaxMsgs),
		MaxBytes:     int(info.Config.MaxBytes),
		MaxAge:       int(info.Config.MaxAge / time.Second),
		Storage:      info.Config.Storage.String(),
		Replicas:     info.Config.Replicas,
		Messages:     int(info.State.Msgs),
		Bytes:        int(info.State.Bytes),
		Consumers:    info.State.Consumers,
		Created:      info.Created.Format(time.RFC3339),
		Sources:      mapSources(info.Sources),
	}, nil
}

// Publish is the resolver for the publish field.
func (r *mutationResolver) Publish(ctx context.Context, subject string, data string) (*model.PublishResult, error) {
	const maxPayload = 1 << 20 // 1 MB
	if len(data) > maxPayload {
		return nil, fmt.Errorf("payload too large: %d bytes (max %d)", len(data), maxPayload)
	}

	ack, err := r.JS.Publish(ctx, subject, []byte(data))
	if err != nil {
		return nil, err
	}

	return &model.PublishResult{
		Stream:   ack.Stream,
		Sequence: int(ack.Sequence),
	}, nil
}

// PublishScheduled is the resolver for the publishScheduled field.
func (r *mutationResolver) PublishScheduled(ctx context.Context, subject string, data string, delay int) (bool, error) {
	const maxPayload = 1 << 20 // 1 MB
	if len(data) > maxPayload {
		return false, fmt.Errorf("payload too large: %d bytes (max %d)", len(data), maxPayload)
	}
	if delay <= 0 {
		return false, fmt.Errorf("delay must be positive, got %d", delay)
	}

	go func() {
		time.Sleep(time.Duration(delay) * time.Second)
		bgCtx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
		defer cancel()
		_, err := r.JS.Publish(bgCtx, subject, []byte(data))
		if err != nil {
			fmt.Printf("scheduled publish to %s failed: %v\n", subject, err)
		}
	}()

	return true, nil
}

// ConsumerCreate is the resolver for the consumerCreate field.
func (r *mutationResolver) ConsumerCreate(ctx context.Context, stream string, name string, filterSubject *string, filterSubjects []string, deliverPolicy *string, ackPolicy *string, ackWait *int, maxDeliver *int, maxAckPending *int, replicas *int, description *string) (*model.ConsumerInfo, error) {
	cfg := jetstream.ConsumerConfig{
		Name:    name,
		Durable: name,
	}

	if filterSubject != nil && *filterSubject != "" {
		cfg.FilterSubject = *filterSubject
	}
	if len(filterSubjects) > 0 {
		cfg.FilterSubjects = filterSubjects
	}

	if deliverPolicy != nil {
		switch *deliverPolicy {
		case "last":
			cfg.DeliverPolicy = jetstream.DeliverLastPolicy
		case "new":
			cfg.DeliverPolicy = jetstream.DeliverNewPolicy
		case "last_per_subject":
			cfg.DeliverPolicy = jetstream.DeliverLastPerSubjectPolicy
		default:
			cfg.DeliverPolicy = jetstream.DeliverAllPolicy
		}
	}

	if ackPolicy != nil {
		switch *ackPolicy {
		case "none":
			cfg.AckPolicy = jetstream.AckNonePolicy
		case "all":
			cfg.AckPolicy = jetstream.AckAllPolicy
		default:
			cfg.AckPolicy = jetstream.AckExplicitPolicy
		}
	}

	if ackWait != nil {
		cfg.AckWait = time.Duration(*ackWait) * time.Second
	}
	if maxDeliver != nil {
		cfg.MaxDeliver = *maxDeliver
	}
	if maxAckPending != nil {
		cfg.MaxAckPending = *maxAckPending
	}
	if replicas != nil {
		cfg.Replicas = *replicas
	}
	if description != nil {
		cfg.Description = *description
	}

	cons, err := r.JS.CreateOrUpdateConsumer(ctx, stream, cfg)
	if err != nil {
		return nil, err
	}

	ci, err := cons.Info(ctx)
	if err != nil {
		return nil, err
	}

	return mapConsumerInfo(ci), nil
}

// ConsumerDelete is the resolver for the consumerDelete field.
func (r *mutationResolver) ConsumerDelete(ctx context.Context, stream string, name string) (bool, error) {
	err := r.JS.DeleteConsumer(ctx, stream, name)
	if err != nil {
		return false, err
	}
	return true, nil
}

// ConsumerPause is the resolver for the consumerPause field.
func (r *mutationResolver) ConsumerPause(ctx context.Context, stream string, name string, pauseUntil string) (bool, error) {
	t, err := parseRFC3339(pauseUntil)
	if err != nil {
		return false, fmt.Errorf("invalid pauseUntil format (expected RFC3339): %w", err)
	}
	_, err = r.JS.PauseConsumer(ctx, stream, name, t)
	if err != nil {
		return false, err
	}
	return true, nil
}

// ConsumerResume is the resolver for the consumerResume field.
func (r *mutationResolver) ConsumerResume(ctx context.Context, stream string, name string) (bool, error) {
	_, err := r.JS.ResumeConsumer(ctx, stream, name)
	if err != nil {
		return false, err
	}
	return true, nil
}

// KeyValues is the resolver for the keyValues field.
func (r *queryResolver) KeyValues(ctx context.Context) ([]*model.KeyValue, error) {
	var result []*model.KeyValue

	names := r.JS.KeyValueStoreNames(ctx)
	for name := range names.Name() {
		kv, err := r.JS.KeyValue(ctx, name)
		if err != nil {
			return nil, err
		}

		status, err := kv.Status(ctx)
		if err != nil {
			return nil, err
		}

		ttlSeconds := 0
		if status.TTL() > 0 {
			ttlSeconds = int(status.TTL() / time.Second)
		}

		result = append(result, &model.KeyValue{
			Bucket:       status.Bucket(),
			History:      int(status.History()),
			TTL:          ttlSeconds,
			Storage:      status.BackingStore(),
			Bytes:        int(status.Bytes()),
			Values:       int(status.Values()),
			IsCompressed: status.IsCompressed(),
		})
	}

	if err := names.Error(); err != nil {
		return nil, err
	}

	return result, nil
}

// Streams is the resolver for the streams field.
func (r *queryResolver) Streams(ctx context.Context) ([]*model.StreamInfo, error) {
	var result []*model.StreamInfo

	streams := r.JS.ListStreams(ctx)
	for si := range streams.Info() {
		subjects := make([]string, 0, len(si.Config.Subjects))
		subjects = append(subjects, si.Config.Subjects...)

		result = append(result, &model.StreamInfo{
			Name:         si.Config.Name,
			Subjects:     subjects,
			Retention:    si.Config.Retention.String(),
			MaxConsumers: si.Config.MaxConsumers,
			MaxMsgs:      int(si.Config.MaxMsgs),
			MaxBytes:     int(si.Config.MaxBytes),
			MaxAge:       int(si.Config.MaxAge / time.Second),
			Storage:      si.Config.Storage.String(),
			Replicas:     si.Config.Replicas,
			Messages:     int(si.State.Msgs),
			Bytes:        int(si.State.Bytes),
			Consumers:    si.State.Consumers,
			Created:      si.Created.Format(time.RFC3339),
			Sources:      mapSources(si.Sources),
		})
	}

	if err := streams.Err(); err != nil {
		return nil, err
	}

	return result, nil
}

// KvKeys is the resolver for the kvKeys field.
func (r *queryResolver) KvKeys(ctx context.Context, bucket string) ([]string, error) {
	kv, err := r.JS.KeyValue(ctx, bucket)
	if err != nil {
		return nil, err
	}

	lister, err := kv.ListKeys(ctx)
	if err != nil {
		return nil, err
	}

	var keys []string
	for key := range lister.Keys() {
		keys = append(keys, key)
	}

	return keys, nil
}

// KvGet is the resolver for the kvGet field.
func (r *queryResolver) KvGet(ctx context.Context, bucket string, key string) (*model.KVEntry, error) {
	kv, err := r.JS.KeyValue(ctx, bucket)
	if err != nil {
		return nil, err
	}

	entry, err := kv.Get(ctx, key)
	if err != nil {
		if errors.Is(err, jetstream.ErrKeyNotFound) {
			return nil, nil
		}
		return nil, err
	}

	return &model.KVEntry{
		Key:      entry.Key(),
		Value:    string(entry.Value()),
		Revision: int(entry.Revision()),
		Created:  entry.Created().Format(time.RFC3339),
	}, nil
}

// StreamMessages is the resolver for the streamMessages field.
func (r *queryResolver) StreamMessages(ctx context.Context, stream string, last int, startSeq *int, startTime *string, endTime *string, subject *string) ([]*model.StreamMessage, error) {
	const maxMessages = 100
	if last <= 0 {
		return nil, fmt.Errorf("last must be > 0")
	}
	if last > maxMessages {
		return nil, fmt.Errorf("last exceeds maximum of %d messages", maxMessages)
	}

	// Parse time filters
	var endTimeVal time.Time
	hasEndTime := false
	if endTime != nil {
		t, err := parseRFC3339(*endTime)
		if err != nil {
			return nil, fmt.Errorf("invalid endTime format (expected RFC3339): %w", err)
		}
		endTimeVal = t
		hasEndTime = true
	}

	s, err := r.JS.Stream(ctx, stream)
	if err != nil {
		return nil, err
	}

	info, err := s.Info(ctx)
	if err != nil {
		return nil, err
	}

	if info.State.Msgs == 0 {
		return []*model.StreamMessage{}, nil
	}

	// Build ordered consumer config
	cfg := jetstream.OrderedConsumerConfig{}

	// Subject filter
	if subject != nil && *subject != "" {
		cfg.FilterSubjects = []string{*subject}
	}

	// Determine delivery policy
	if startTime != nil {
		t, err := parseRFC3339(*startTime)
		if err != nil {
			return nil, fmt.Errorf("invalid startTime format (expected RFC3339): %w", err)
		}
		cfg.DeliverPolicy = jetstream.DeliverByStartTimePolicy
		cfg.OptStartTime = &t
	} else if startSeq != nil {
		if *startSeq < 1 {
			return nil, fmt.Errorf("startSeq must be >= 1")
		}
		cfg.DeliverPolicy = jetstream.DeliverByStartSequencePolicy
		cfg.OptStartSeq = uint64(*startSeq)
	} else {
		// Default: read last N messages from the end
		// Calculate start sequence to get roughly 'last' messages
		lastSeq := info.State.LastSeq
		firstSeq := info.State.FirstSeq
		calcStart := lastSeq - uint64(last) + 1
		if calcStart < firstSeq || calcStart > lastSeq {
			calcStart = firstSeq
		}
		cfg.DeliverPolicy = jetstream.DeliverByStartSequencePolicy
		cfg.OptStartSeq = calcStart
	}

	// Create ordered consumer (ephemeral, auto-cleanup)
	cons, err := s.OrderedConsumer(ctx, cfg)
	if err != nil {
		return nil, fmt.Errorf("failed to create consumer: %w", err)
	}

	// Fetch messages
	fetchCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	msgs, err := cons.Fetch(last, jetstream.FetchMaxWait(3*time.Second))
	if err != nil {
		return nil, fmt.Errorf("failed to fetch messages: %w", err)
	}

	var result []*model.StreamMessage
loop:
	for msg := range msgs.Messages() {
		select {
		case <-fetchCtx.Done():
			break loop
		default:
		}

		meta, err := msg.Metadata()
		if err != nil {
			continue
		}

		msgTime := meta.Timestamp

		// Apply endTime filter
		if hasEndTime && msgTime.After(endTimeVal) {
			break
		}

		result = append(result, &model.StreamMessage{
			Sequence:  int(meta.Sequence.Stream),
			Subject:   msg.Subject(),
			Data:      string(msg.Data()),
			Published: msgTime.Format(time.RFC3339Nano),
		})
	}

	if msgs.Error() != nil {
		// Ignore timeout errors — they just mean no more messages
		if msgs.Error().Error() != "nats: timeout" {
			return nil, msgs.Error()
		}
	}

	return result, nil
}

// Consumers is the resolver for the consumers field.
func (r *queryResolver) Consumers(ctx context.Context, stream string) ([]*model.ConsumerInfo, error) {
	s, err := r.JS.Stream(ctx, stream)
	if err != nil {
		return nil, err
	}

	var result []*model.ConsumerInfo

	lister := s.ListConsumers(ctx)
	for ci := range lister.Info() {
		result = append(result, mapConsumerInfo(ci))
	}

	if err := lister.Err(); err != nil {
		return nil, err
	}

	return result, nil
}

// ConsumerInfo is the resolver for the consumerInfo field.
func (r *queryResolver) ConsumerInfo(ctx context.Context, stream string, name string) (*model.ConsumerInfo, error) {
	cons, err := r.JS.Consumer(ctx, stream, name)
	if err != nil {
		if errors.Is(err, jetstream.ErrConsumerNotFound) {
			return nil, nil
		}
		return nil, err
	}

	ci, err := cons.Info(ctx)
	if err != nil {
		return nil, err
	}

	return mapConsumerInfo(ci), nil
}

// StreamSubscribe is the resolver for the streamSubscribe field.
func (r *subscriptionResolver) StreamSubscribe(ctx context.Context, stream string, subject *string) (<-chan *model.StreamMessage, error) {
	s, err := r.JS.Stream(ctx, stream)
	if err != nil {
		return nil, err
	}

	// Build ordered consumer config — deliver only new messages
	cfg := jetstream.OrderedConsumerConfig{
		DeliverPolicy: jetstream.DeliverNewPolicy,
	}
	if subject != nil && *subject != "" {
		cfg.FilterSubjects = []string{*subject}
	}

	cons, err := s.OrderedConsumer(ctx, cfg)
	if err != nil {
		return nil, fmt.Errorf("failed to create consumer: %w", err)
	}

	// Start consuming
	iter, err := cons.Messages()
	if err != nil {
		return nil, fmt.Errorf("failed to start consuming: %w", err)
	}

	ch := make(chan *model.StreamMessage, 1)

	go func() {
		defer close(ch)
		defer iter.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			default:
			}

			msg, err := iter.Next()
			if err != nil {
				return
			}

			meta, err := msg.Metadata()
			if err != nil {
				continue
			}

			sm := &model.StreamMessage{
				Sequence:  int(meta.Sequence.Stream),
				Subject:   msg.Subject(),
				Data:      string(msg.Data()),
				Published: meta.Timestamp.Format(time.RFC3339Nano),
			}

			select {
			case ch <- sm:
			case <-ctx.Done():
				return
			}
		}
	}()

	return ch, nil
}

// Mutation returns MutationResolver implementation.
func (r *Resolver) Mutation() MutationResolver { return &mutationResolver{r} }

// Query returns QueryResolver implementation.
func (r *Resolver) Query() QueryResolver { return &queryResolver{r} }

// Subscription returns SubscriptionResolver implementation.
func (r *Resolver) Subscription() SubscriptionResolver { return &subscriptionResolver{r} }

type mutationResolver struct{ *Resolver }
type queryResolver struct{ *Resolver }
type subscriptionResolver struct{ *Resolver }
